% This is not an official submission to SIGIR, this is only an assignment for a course about mapreduce at the University of Twente

\documentclass{acm_proc_article-sp}

\begin{document}

\title{Analyzing the correlation between Movie Sentiment and Sales Performance}
\subtitle{Using MapReduce with Hadoop}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Joost van Doorn\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}
% 2nd. author
\alignauthor
Bas Janssen\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}
% 3rd. author
\alignauthor Niek Tax\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{30 January 2014}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
A lot of work has been done in using sentiment analysis on online reviews or blogs for sales forecasting. However, no work has been done on using sentiment analysis on a web crawl. With Hadoop we extracted all sentences matching a IMDb top250 movie title and extracted the sentiments for these sentences. With Kendall's $\tau$ in combination with the AS71 algorithm we were not able to find a correlation between the percentage of either 'very positive' as well as 'very negative' sentences and the box office revenue as well as the IMDb rating. Therefore we can not conclude that we could use the movie sentiment based on a web crawl for prediction of either sales performance or IMDb rating.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.3.3}{Information Search and Retrieval}{Text Mining}

\terms{Measurement}

\keywords{Sentiment analysis, hadoop, mapreduce, movies} % NOT required for Proceedings

\section{Introduction}
With the emergence of the Web2.0 came a staggering increase of online reviews for, amongst others, movies. Reviews on the web often appear shortly after a movie's cinema release, possibly already during the movie's opening night on social media like Twitter. 

Several studies have shown the predictive power of online movie review sentiment to movie sales performance \cite{Mishne2006, Liu2007, Dellarocas2007, Asur2010, Joshi2010, Yu2012}. Existing research in the predictive power of online movie review sentiment have limited scope, focusing on one blogging platform or social medium. The release of the Common Crawl\footnote{commoncrawl.org} data set allows us to research the applicability of movie sentiments on a large crawl of the web.  

We also investigate the level of agreement between online movie review sentiment and Internet Movie Database (IMDb\footnote{imdb.com}) movie rating. A high agreement between IMDb ratings and online movie review sentiment would 1) show that IMDb movie ratings reflect a movie's overall appreciation the web, and 2) make it possible for the movie industry to obtain rating input data for sales forecasting models in an earlier stage, as the minimal sample size needed for reliable ratings will be reached earlier on whole web than on a single resource. A previous study in this area by Oghina et al \cite{Oghina2012} achieved a Spearman's $\rho$ of 0.8915 between IMDb rating and a Twitter and Youtube data based machine learning model. No similar web crawl based study is known to the authors.

\section{The {\secit Body} of The Paper}
We use a publicly available subset of the IMDb database\footnote{ftp://ftp.fu-berlin.de/pub/misc/movies/database/} consisting of over 500 000 movies and their ratings. For the results described in this paper we used the top 250 Movies of IMDb. We used this subset as this set is likely to be more frequent than other sets.

Using a user-defined function (UDF) in Apache Pig\footnote{pig.apache.org} we filter the Text Only files (containing only textual content of the HTML body) from the Common Crawl data set to obtain the web content of only those pages that contain one of the movie titles in our movie set. We split this content into sentences using the sentence splitter that comes with the Stanford CoreNLP\footnote{nlp.stanford.edu/software/corenlp.shtml} Tokenizer. The outputted sentences are again filtered on presence of a movie title from our movie set to obtain all sentences in Common Crawl that mention a movie in our movie set.

Socher et al \cite{Socher2013} made their recursive neural tensor network sentence-level sentiment analysis model for predicting review sentiment publicly available as part of the Stanford CoreNLP library. We use this sentiment analysis model to construct movie sentiment key-value pairs for each sentence, with sentiment being an element from the set \texttt{\{\mbox{---},--,0,+,\mbox{++}\}}. A reduce task transforms these movie sentiment pairs into counts of the different sentiment categories for each movie. 

We will use Kendall's tau\cite{Kendall1938} as measure of accordance between movie sentiments and box office revenue and IMDb rating. Using the AS71 algorithm proposed by Best and Gipps\cite{Best1974}, we can calculate the p-value for rejecting the null hypothesis based on the Kendall's tau statistic. Levels of accordance will be tested for percentage of a movie's 'very negative'-sentiments and 'very positive'-sentiments on the one hand and its box office revenue and IMDb rating on the other hand, therefore we state the following hypotheses:
\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
	\item H0: the relation 'very positive'-percentage and box office revenue
	\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
		\item $H0_0$: There does not exist any correlation between 'very positive'-\% and box office revenue
		\item $H0_1$: There does exist a correlation between 'very positive'-\% and box office revenue
	\end{itemize}
	\item H1: the relation 'very negative'-percentage and box office revenue
	\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
		\item $H1_0$: There does not exist any correlation between 'very negative'-\% and box office revenue
		\item $H1_1$: There does exist a correlation between 'very negative'-\% and box office revenue
	\end{itemize}
	\item H2: the relation 'very positive'-percentage and IMDb rating
	\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
		\item $H2_0$: There does not exist any correlation between 'very positive'-\% and IMDb rating
		\item $H2_1$: There does exist a correlation between 'very positive'-\% and IMDb rating
	\end{itemize}
	\item H3: the relation 'very negative'-percentage and IMDb rating
	\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
		\item $H3_0$: There does not exist any correlation between 'very negative'-\% and IMDb rating
		\item $H3_1$: There does exist a correlation between 'very negative'-\% and IMDb rating
	\end{itemize}
\end{itemize}

Hypotheses listed are tested on a 5\%-significance level.

The Pig files, the Pig User Defined Functions, the R script for the statistical analysis and other source files are publicly available on our GitHub repository\footnote{https://github.com/JoostvDoorn/MovieReviewSentimentRankings}.

\subsection{Results}
In about 16 hours the SURFsara Hadoop cluster processed the Common Crawl data set and extracted sentiment sets for each movie. 17 parallel map tasks were running throughout the process. Shorter processing times would have been possible by setting the split factor such that more parallel map tasks would have been used, but did not want to put more load on the cluster than needed. We used a Python script to group the sentiments of each movie into counts for each sentiment category. In total we processed almost half a million sentences. A time-out in the sentiment analysis UDF of 3000ms caused the sentiment analysis of 42.9\% of all sentences to time-out. Table \ref{tab:hypothesis_tests} displays the results of the statistical tests performed on the extracted data.
\begin{table}[!h!p]
\begin{tabular}{l|lll}
Hypothesis & Kendall's $\tau$ & p-value (2-sid.) & Reject $H_0$?\\
\hline
$H0_0$ & 0.146 & 0.10393 & No \\ 
$H1_0$ & 0.151 & 0.087175 & No \\ 
$H2_0$ & 0.00165 & 0.99332 & No \\ 
$H3_0$ & -0.0499 & 0.61564 & No\\ 
\end{tabular}
\caption{Kendall's tau values and p-values for the hypotheses}
\label{tab:hypothesis_tests}
\end{table}

\subsection{Citations}
Citations to articles \cite{bowman:reasoning, clark:pct, braams:babel, herlihy:methodology},
conference
proceedings \cite{clark:pct} or books \cite{salas:calculus, Lamport:LaTeX} listed
in the Bibliography section of your
article will occur throughout the text of your article.
You should use BibTeX to automatically produce this bibliography;
you simply need to insert one of several citation commands with
a key of the item cited in the proper location in
the \texttt{.tex} file \cite{Lamport:LaTeX}.
The key is a short reference you invent to uniquely
identify each work; in this sample document, the key is
the first author's surname and a
word from the title.  This identifying key is included
with each item in the \texttt{.bib} file for your article.

\subsection{Tables}
Because tables cannot be split across pages, the best
placement for them is typically the top of the page
nearest their initial cite.  To
ensure this proper ``floating'' placement of tables, use the
environment \textbf{table} to enclose the table's contents and
the table caption.  The contents of the table itself must go
in the \textbf{tabular} environment, to
be aligned properly in rows and columns, with the desired
horizontal and vertical rules.  Again, detailed instructions
on \textbf{tabular} material
is found in the \textit{\LaTeX\ User's Guide}.

Immediately following this sentence is the point at which
Table 1 is included in the input file; compare the
placement of the table here with the table in the printed
dvi output of this document.

\begin{table}
\centering
\caption{Frequency of Special Characters}
\begin{tabular}{|c|c|l|} \hline
Non-English or Math&Frequency&Comments\\ \hline
\O & 1 in 1,000& For Swedish names\\ \hline
$\pi$ & 1 in 5& Common in math\\ \hline
\$ & 4 in 5 & Used in business\\ \hline
$\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
\hline\end{tabular}
\end{table}


\section{Conclusions}
We could not find a significant correlation between the movie sentiment and either the IMDb ratings or revenue using our method. By investigating a sample of the input of the sentiment analyzer we found that most of the sentences were not related to the movie title found in that sentence. It was most often related to something else or not a good indicator of sentiment. Even though we only looked at a small sample of the sentences compared to the whole dataset, a better selection of relevant sentences is likely to improve performance.

Our approach does not attempt to do a thorough filtering of the sentences set to make sure that we really are matching a sentence that is about the movie as well as a good indicator of sentiment about the movie. For example, if "The Pianist" is found in a sentence, we currently assume that this is about the movie. For certain movies this is likely to work, since the title of the movie is uncommon in normal sentences and when considering a lot of data a few incorrect sentences do not matter that much. Though with our current results this assumption seems flawed, or at least we could not use this to our advantage. Still it is likely to work for some movies like "Forrest Gump" where we do not expect many out context sentences to be found, in contrast to a movie like "The General" (e.g. The General Terms and Conditions, the general assumption). In our current approach we seem to assume that a lot of data fixes everything, even if this data is not selected well.
%\end{document}  % This is where a 'short' article might terminate <--- Should we do this???

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
Our special thanks to Dr. Djoerd Hiemstra for his supervision throughout the research as our supervisor and to IMDb for making the movie ratings available. Furthermore we would like to thank SURFsara for allowing us to run computations on their Hadoop cluster.


%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns

\balancecolumns
% That's all folks!
\end{document}
