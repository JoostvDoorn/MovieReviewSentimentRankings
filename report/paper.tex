\documentclass{sig-alternate-br}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{xcolor,colortbl}
\usepackage[official]{eurosym}
\usepackage{hyperref}
% \url{} als link + fixed-width font
\usepackage{url}

% interpunctie, citations
\usepackage[english]{babel}
\usepackage{csquotes}% Recommended
\usepackage{natbib}


% tabel tool
\usepackage{tabu}


\usepackage{graphicx}
\usepackage{subfig}

\begin{document}
\CopyrightYear{2013} 

\title{Analyzing Movie Sentiment on the Web for Predicting Sales Performance and Movie Appreciation}

\numberofauthors{3}
\author{
\alignauthor Joost van Doorn\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}\\
\alignauthor Bas Janssen\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}\\
\alignauthor Niek Tax\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}\\
}

\maketitle
\begin{abstract}
One day an abstract will appear at this place :).
\end{abstract} 

\keywords{Sentiment Analysis}

\section{Idea}
With the emergence of the Web2.0 came a staggering increase of online reviews for, amongst others, movies. Reviews on the web often appear shortly after a movie's cinema release, possibly already during the movie's opening night on social media like Twitter. 

Several studies have shown the predictive power of online movie review sentiment to movie sales performance \cite{Mishne2006, Liu2007, Dellarocas2007, Asur2010, Joshi2010, Yu2012}. Existing research in the predictive power of online movie review sentiment have limited scope, focusing on one blogging platform or social medium. The release of the Common Crawl\footnote{commoncrawl.org} data set allows us to research the applicability of movie sentiments on a large crawl of the web.  

We also investigate the level of agreement between online movie review sentiment and Internet Movie Database (IMDb\footnote{imdb.com}) movie rating. A high agreement between IMDb ratings and online movie review sentiment would 1) show that IMDb movie ratings reflect a movie's overall appreciation the web, and 2) make it possible for the movie industry to obtain rating input data for sales forecasting models in an earlier stage, as the minimal sample size needed for reliable ratings will be reached earlier on whole web than on a single resource. A previous study in this area by Oghina et al \cite{Oghina2012} achieved a Spearman's $\rho$ of 0.8915 between IMDb rating and a Twitter and Youtube data based machine learning model. No similar web crawl based study is known to the authors.

\section{Method}
We use a publicly available subset of the IMDb database\footnote{ftp://ftp.fu-berlin.de/pub/misc/movies/database/} consisting of over 500 000 movies and their ratings.

Using a user-defined function (UDF) in Pig we filter the Text Only files (containing only textual content of the HTML body) from the Common Crawl data set to obtain the web content of only those pages that contain one of the movie titles in our movie set. We split this content into sentences using the sentence splitter that comes with the Stanford CoreNLP\footnote{nlp.stanford.edu/software/corenlp.shtml} Tokenizer. The outputted sentences are again filtered on presence of a movie title from our movie set to obtain all sentences in Common Crawl that mention a movie in our movie set.

Socher et al \cite{Socher2013} made their recursive neural tensor network sentence-level sentiment analysis model for predicting review sentiment publicly available as part of the Stanford CoreNLP library. We use this sentiment analysis model to construct movie sentiment key-value pairs for each sentence, with sentiment being an element from the set \texttt{\{\mbox{---},--,0,+,\mbox{++}\}} . A reduce task transforms these movie sentiment pairs into counts of the different sentiment categories for each movie. The Pig files, Pig User Defined Functions and other source files are publicly available on the GitHub repository\footnote{https://github.com/JoostvDoorn/MovieReviewSentimentRankings}.

\section{Results}
Due to some unexpected difficulties that arose on the SARA test set that did not occur before during local testing we do not have a finished run on the complete data set yet. We did manage to finish a run on all but one data file of the SARA test set (the error that still is to be fixed only occurred on this data set). This test set run finished in 20 minutes. If we linearly scale this running time to the full data set we can expect the full data set to be processed in (25TB/6GB times as long TODO: dit stuk met running tijd wat aanpassen zodat het minder kut lijkt). We expect to find a correlation between the IMDb ratings and the general sentiment on the web. As IMDb is the most popular source for movie information, we expect their reviewers to be a fair representation of the general population. In the same sense we expect this of the Common Crawl dataset.

% According to Alexa, imdb is the 44 most popular site worldwide


Although we generally expect IMDb to reach a fair share of the general population, we do expect some differences. Some groups may be underrepresented on IMDb. This may be because this group prefers to use another website. This could cause some categories to get different ratings on IMDb than our analysis of the general web.



\section{Discussion}
The online movie review sentiment analysis may be used in different ways. Movies can be ranked based on their sentiment. Sentiment can be used as a predictor of a movies success and will reach a reasonable sample size much faster than a single resource. 
Movies are likely to show different types of sentiment distributions which could be an indicator of the distribution of the fanbase, some movies may have loyal fans and just as many who absolutely hate a movie. 

Our current script at the moment is still unable to validate that a movie title is really meant as a movie title or that it is used in a normal sentence without referring to a movie. For example, if "The Pianist" is found in a sentence, we currently assume that the movie is meant. For a big dataset, this assumption could turn out better than expected because more data could perform better than a better algorithm. However, we except that this algorithm is just too bad to perform better. Some movies like "Forrest Gump" do not need any more optimization because the title is not used in out of context sentences very much.

Currently, we still are not processing enough data to calculate a rating. "American History X" for example is a good example of a string which most times will refer to the movie instead of something else. Therefore, you will expect a good result for this movie. However, in the current data set, only one sentence contains the movie title and therefore a rating cannot be computed.

\section{Acknowledgement}
Our special thanks to Dr. Djoerd Hiemstra for his supervision throughout the research as our supervisor and to IMDb for making the movie ratings available. Furthermore we would like to thank SURFsara for allowing us to run computations on their Hadoop cluster.
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.

\bibliographystyle{abbrv}
\bibliography{paper}

\balancecolumns

\onecolumn

\end{document}
