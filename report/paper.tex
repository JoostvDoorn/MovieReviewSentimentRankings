\documentclass{sig-alternate-br}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{xcolor,colortbl}
\usepackage[official]{eurosym}
\usepackage{hyperref}
% \url{} als link + fixed-width font
\usepackage{url}

% interpunctie, citations
\usepackage[english]{babel}
\usepackage{csquotes}% Recommended
\usepackage{natbib}

% tabel tool
\usepackage{tabu}
\usepackage{graphicx}
\usepackage{subfig}

\begin{document}
\CopyrightYear{2013} 

\title{Analyzing Movie Sentiment on the Web for Predicting Sales Performance and Movie Appreciation}

\numberofauthors{3}
\author{
\alignauthor Joost van Doorn\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}\\
\alignauthor Bas Janssen\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}\\
\alignauthor Niek Tax\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}\\
}

\maketitle
\begin{abstract}
A lot of work has been done in using sentiment analysis on online reviews or blogs for sales forecasting. However, no work has been done on using sentiment analysis on a web crawl. With Hadoop we extracted all sentences matching a IMDb top250 movie title and extracted the sentiments for these sentences. With Kendall's $\tau$ in combination with the AS71 algorithm we were not able to find a correlation between the percentage of either 'very positive' as well as 'very negative' sentences and the box office revenue as well as the IMDb rating. Therefore we can not conclude that we could use the movie sentiment based on a web crawl for prediction of either sales performance or IMDb rating.
\end{abstract} 

\keywords{Sentiment Analysis}

\section{Idea}
With the emergence of the Web2.0 came a staggering increase of online reviews for, amongst others, movies. Reviews on the web often appear shortly after a movie's cinema release, possibly already during the movie's opening night on social media like Twitter. 

Several studies have shown the predictive power of online movie review sentiment to movie sales performance \cite{Mishne2006, Liu2007, Dellarocas2007, Asur2010, Joshi2010, Yu2012}. Existing research in the predictive power of online movie review sentiment have limited scope, focusing on one blogging platform or social medium. The release of the Common Crawl\footnote{commoncrawl.org} data set allows us to research the applicability of movie sentiments on a large crawl of the web.  

We also investigate the level of agreement between online movie review sentiment and Internet Movie Database (IMDb\footnote{imdb.com}) movie rating. A high agreement between IMDb ratings and online movie review sentiment would 1) show that IMDb movie ratings reflect a movie's overall appreciation the web, and 2) make it possible for the movie industry to obtain rating input data for sales forecasting models in an earlier stage, as the minimal sample size needed for reliable ratings will be reached earlier on whole web than on a single resource. A previous study in this area by Oghina et al \cite{Oghina2012} achieved a Spearman's $\rho$ of 0.8915 between IMDb rating and a Twitter and Youtube data based machine learning model. No similar web crawl based study is known to the authors.

\section{Method}
We use a publicly available subset of the IMDb database\footnote{ftp://ftp.fu-berlin.de/pub/misc/movies/database/} consisting of over 500 000 movies and their ratings.

Using a user-defined function (UDF) in Pig we filter the Text Only files (containing only textual content of the HTML body) from the Common Crawl data set to obtain the web content of only those pages that contain one of the movie titles in our movie set. We split this content into sentences using the sentence splitter that comes with the Stanford CoreNLP\footnote{nlp.stanford.edu/software/corenlp.shtml} Tokenizer. The outputted sentences are again filtered on presence of a movie title from our movie set to obtain all sentences in Common Crawl that mention a movie in our movie set.

Socher et al \cite{Socher2013} made their recursive neural tensor network sentence-level sentiment analysis model for predicting review sentiment publicly available as part of the Stanford CoreNLP library. We use this sentiment analysis model to construct movie sentiment key-value pairs for each sentence, with sentiment being an element from the set \texttt{\{\mbox{---},--,0,+,\mbox{++}\}}. A reduce task transforms these movie sentiment pairs into counts of the different sentiment categories for each movie. 

We will use Kendall's tau\cite{Kendall1938} as measure of accordance between movie sentiments and box office revenue and IMDb rating. Using the AS71 algorithm proposed by Best and Gipps\cite{Best1974}, we can calculate the p-value for rejecting the null hypothesis based on the Kendall's tau statistic. Levels of accordance will be tested for percentage of a movie's 'very negative'-sentiments and 'very positive'-sentiments on the one hand and its box office revenue and IMDb rating on the other hand, therefore we state the following hypotheses:
\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
	\item H0: the relation 'very positive'-percentage and box office revenue
	\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
		\item $H0_0$: There does not exist any correlation between 'very positive'-\% and box office revenue
		\item $H0_1$: There does exist a correlation between 'very positive'-\% and box office revenue
	\end{itemize}
	\item H1: the relation 'very negative'-percentage and box office revenue
	\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
		\item $H1_0$: There does not exist any correlation between 'very negative'-\% and box office revenue
		\item $H1_1$: There does exist a correlation between 'very negative'-\% and box office revenue
	\end{itemize}
	\item H2: the relation 'very positive'-percentage and IMDb rating
	\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
		\item $H2_0$: There does not exist any correlation between 'very positive'-\% and IMDb rating
		\item $H2_1$: There does exist a correlation between 'very positive'-\% and IMDb rating
	\end{itemize}
	\item H3: the relation 'very negative'-percentage and IMDb rating
	\begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
		\item $H3_0$: There does not exist any correlation between 'very negative'-\% and IMDb rating
		\item $H3_1$: There does exist a correlation between 'very negative'-\% and IMDb rating
	\end{itemize}
\end{itemize}

Hypotheses listed are tested on a 5\%-significance level.

The Pig files, the Pig User Defined Functions, the R script for the statistical analysis and other source files are publicly available on our GitHub repository\footnote{https://github.com/JoostvDoorn/MovieReviewSentimentRankings}.

\section{Results}
In about 16 hours the SURFsara Hadoop cluster processed the Common Crawl data set and extracted sentiment sets for each movie. 17 parallel map tasks were running throughout the process. Shorter processing times would have been possible by setting the split factor such that more parallel map tasks would have been used, but did not want to put more load on the cluster than needed. We used a python script to group the sentiments of each movie into counts for each sentiment category. In total we processed almost half a million sentences. A time-out in the sentiment analysis UDF of 3000ms caused the sentiment analysis of 42.9\% of all sentences to time-out. Table \ref{tab:hypothesis_tests} displays the results of the statistical tests performed on the extracted data.
\begin{table}[!h!p]
\begin{tabular}{l|lll}
Hypothesis & Kendall's $\tau$ & p-value (2-sid.) & Reject $H_0$?\\
\hline
$H0_0$ & 0.146 & 0.10393 & No \\ 
$H1_0$ & 0.151 & 0.087175 & No \\ 
$H2_0$ & 0.00165 & 0.99332 & No \\ 
$H3_0$ & -0.0499 & 0.61564 & No\\ 
\end{tabular}
\caption{Kendall's tau values and p-values for the hypotheses}
\label{tab:hypothesis_tests}
\end{table}

\section{Discussion}
We could not find a significant correlation between the movie sentiment and either the IMDb ratings or revenue.

Our approach does not attempt to do a thorough filtering of the sentences set to make sure that we really are matching a sentence that is about the movie as well as a good indicator of sentiment about the movie. For example, if "The Pianist" is found in a sentence, we currently assume that this is about the movie. For certain movies this is likely to work, since the title of the movie is uncommon in normal sentences and when considering a lot of data a few incorrect sentences do not matter that much. Though with our current results this assumption seems flawed, or at least we could not use this to our advantage. Still it is likely to work for some movies like "Forrest Gump" where we do not expect many out context sentences to be found, in contrast to a movie like "The General" (e.g. The General Terms and Conditions, the general assumption). In our current approach we seem to assume that a lot of data fixes everything, even if this data is not selected well.

By investigating a sample of the input of the sentiment analyzer we found that most of the sentences were not related to the movie title found in that sentence. It was most often related to something else or not a good indicator of sentiment. Even though we only looked at a small sample of the sentences compared to the whole dataset, a better selection of relevant sentences is likely to improve performance.

\section{Acknowledgement}
Our special thanks to Dr. Djoerd Hiemstra for his supervision throughout the research as our supervisor and to IMDb for making the movie ratings available. Furthermore we would like to thank SURFsara for allowing us to run computations on their Hadoop cluster.
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.

\bibliographystyle{abbrv}
\bibliography{paper}

\balancecolumns

\onecolumn

\end{document}
